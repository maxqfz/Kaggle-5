{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lung segmentation <br/>\n",
    "Copyright (C) 2017 Therapixel (Pierre Fillard).\n",
    "\n",
    "Input data: LIDC (https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI) with\n",
    "LUNA16 lung segmentations (https://luna16.grand-challenge.org/data/). <br />\n",
    "Beforehant, all series shall be converted to a volumetric format (ITK MHD). Filenames\n",
    "shall match the UID of each series. Binaries in the tools/ folder can be used for that \n",
    "(dataImporter, seriesExporter).\n",
    "\n",
    "Annotation files are provided in csv format. Those depict positions (in real world\n",
    "coordinates) of the series identified by their series UID (globally unique) with a 1\n",
    "when inside the lung, and 0 otherwise. The labels 1/0 were obtained from the lung\n",
    "segmentations provided by LUNA.\n",
    "\n",
    "This notebook will guide you through the process of training a deep net to classify\n",
    "nodules vs non-nodules. The following steps are involved:\n",
    "- data conversion: all annotations are turned into h5 arrays by extracting a patch\n",
    "of size 64x64x64 around each position. Images are all resampled to have the same\n",
    "voxel size of 2x2x2.\n",
    "- model training: 4xGPUs were used to train this model using data-parallelism. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import glob\n",
    "import time\n",
    "from time import sleep\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =  \"0,1,2,3\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected, convolution2d, flatten, batch_norm, max_pool2d, dropout, l2_regularizer\n",
    "from tensorflow.python.ops.nn import relu, elu, relu6, relu1, sigmoid, tanh, softmax\n",
    "from tensorflow.python.ops import variable_scope\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import lidc as lidc\n",
    "import TherapixelDL.image as tpxdli\n",
    "from six.moves import xrange\n",
    "import scipy as sp\n",
    "from scipy import ndimage\n",
    "from TherapixelDL.confusionmatrix import ConfusionMatrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import SimpleITK as sitk\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(lidc)\n",
    "importlib.reload(tpxdli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def readCSV(filename):\n",
    "    lines = []\n",
    "    with open(filename, 'r') as f:\n",
    "        csvreader = csv.reader(f)\n",
    "        for line in csvreader:\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def csv_to_h5(input_file, data_directory, output_file):\n",
    "    inputs = readCSV(input_file)\n",
    "    inputs = inputs[1:] # skip header\n",
    "    input_dict={}\n",
    "    total_count = 0\n",
    "    for i in range(len(inputs)):\n",
    "        struct = inputs[i]\n",
    "        seriesuid = struct[0]\n",
    "        if seriesuid not in input_dict:\n",
    "            input_dict[seriesuid] = []\n",
    "        pos = [float(struct[1]),float(struct[2]),float(struct[3]),float(struct[4])]\n",
    "        input_dict[seriesuid].append(pos)\n",
    "        total_count +=1\n",
    "        \n",
    "    target_spacing = [2.,2.,2.]\n",
    "    patch_size = 64\n",
    "    offset = patch_size//2\n",
    "\n",
    "    patches = np.zeros(shape=(total_count,patch_size,patch_size,patch_size), dtype=np.float32)\n",
    "    labels = np.zeros(shape=(total_count), dtype=np.int32)\n",
    "    ids = np.zeros(shape=(total_count), dtype=\"S100\")\n",
    "\n",
    "    index = 0\n",
    "    for seriesuid in input_dict:\n",
    "        print('processing series', seriesuid,'%d/%d'%(index+1,total_count))\n",
    "        series_filename = data_directory + '/' + seriesuid + '.mhd'\n",
    "        itk_image = lidc.load_itk_image(series_filename)\n",
    "        volume, origin, spacing, orientation = lidc.parse_itk_image(itk_image)\n",
    "\n",
    "        padding_value = volume.min()\n",
    "        img_z_orig, img_y_orig, img_x_orig = volume.shape\n",
    "        img_z_new = int(np.round(img_z_orig*spacing[2]/target_spacing[2]))\n",
    "        img_y_new = int(np.round(img_y_orig*spacing[1]/target_spacing[1]))\n",
    "        img_x_new = int(np.round(img_x_orig*spacing[0]/target_spacing[0]))\n",
    "\n",
    "        itk_image = lidc.resample_itk_image(itk_image, [img_x_new,img_y_new,img_z_new], target_spacing, int(padding_value))\n",
    "\n",
    "        volume, origin, spacing, orientation = lidc.parse_itk_image(itk_image)\n",
    "        volume = volume.astype(np.float32)\n",
    "        volume = lidc.normalizePlanes(volume)\n",
    "        volume = np.pad(volume, ((offset,offset),(offset,offset),(offset,offset)), # pad to center\n",
    "                        'constant', constant_values=((0, 0),(0, 0),(0, 0)))  \n",
    "\n",
    "        positions = input_dict[seriesuid]\n",
    "\n",
    "        for i in range(len(positions)):\n",
    "            pos = positions[i]        \n",
    "            kk,jj,ii = lidc.worldToVoxelCoord(pos[0:3],origin=origin,spacing=spacing,orientation=orientation)\n",
    "            kk = int(round(kk))\n",
    "            jj = int(round(jj))\n",
    "            ii = int(round(ii))\n",
    "            patches[index] = volume[kk:kk+patch_size,jj:jj+patch_size,ii:ii+patch_size]\n",
    "            labels[index] = pos[3]\n",
    "            ids[index]=seriesuid\n",
    "            index +=1\n",
    "\n",
    "    h5_file = h5.File(output_file, 'w')\n",
    "    h5_file.create_dataset('PATCHES', data = patches, dtype=np.float32)\n",
    "    h5_file.create_dataset('LABELS', data = labels, dtype=np.int32)\n",
    "    h5_file.create_dataset('ID', data = ids, dtype=\"S100\")\n",
    "    h5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_directory = '/media/data/LIDC/LIDC-MHD/'\n",
    "\n",
    "csv_to_h5('lung_segmentation_positions.csv', data_directory, 'lung_segmentation_positions.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# hyperameters of the model\n",
    "channels = 1\n",
    "scalings=None #np.array([1.0, 1.5])\n",
    "offsets=None #np.array([0.0, -0.05])\n",
    "depth = 64\n",
    "height = 64\n",
    "width = 64\n",
    "num_gpus = 2\n",
    "batch_size = 32\n",
    "patch_size = 64\n",
    "gpu_mem_ratio = 1.0\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def readAndSplitHDF5(filename, val_ratio=0.1, seed=1234):\n",
    "    h5_file = h5.File(filename, 'r')\n",
    "    patches = h5_file['PATCHES'][...]\n",
    "    labels = h5_file['LABELS'][...]\n",
    "    ids = h5_file['ID'][...]\n",
    "    h5_file.close()\n",
    "\n",
    "    indices = np.arange(patches.shape[0])\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(indices)\n",
    "    val_count = max(int(patches.shape[0]*val_ratio), batch_size*num_gpus)\n",
    "\n",
    "    validation_data = patches[indices[:val_count]]\n",
    "    validation_targets = labels[indices[:val_count]]\n",
    "    train_data = patches[indices[val_count:]]\n",
    "    train_targets = labels[indices[val_count:]]\n",
    "    \n",
    "    return train_data, train_targets, validation_data, validation_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data, train_targets, validation_data, validation_targets = readAndSplitHDF5('/media/data/LIDC/lung_segmentation_patches_64.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_hn_data, train_hn_targets, validation_hn_data, validation_hn_targets = readAndSplitHDF5('/media/data/LIDC/lung_segmentation_hard_negs_1_patches_64.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_hn2_data, train_hn2_targets, validation_hn2_data, validation_hn2_targets = readAndSplitHDF5('/media/data/LIDC/lung_segmentation_hard_negs_2_patches_64.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_hn3_data, train_hn3_targets, validation_hn3_data, validation_hn3_targets = readAndSplitHDF5('/media/data/LIDC/lung_segmentation_hard_negs_3_patches_64.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "shift_range = 0.05\n",
    "image_gen_3d = tpxdli.ImageDataGenerator3D(rotation_range=10.0, width_shift_range=shift_range, height_shift_range=shift_range, depth_shift_range=shift_range,\n",
    "                                           shear_range=0.1, zoom_range=np.array([0.95,1.05], dtype=np.float32), horizontal_flip=True, vertical_flip=True, depth_flip=True,\n",
    "                                           windowing_scale_range=0.0, windowing_intercept_range=0.0,\n",
    "                                           dim_ordering = 'tf')\n",
    "# do not augment validation batch to simulate real-life data\n",
    "image_gen_3d_val = tpxdli.ImageDataGenerator3D(rotation_range=0.0, width_shift_range=0.0, height_shift_range=0.0, depth_shift_range=0.0,\n",
    "                                           shear_range=0.0, zoom_range=np.array([1.0,1.0], dtype=np.float32), horizontal_flip=False, vertical_flip=False, depth_flip=False,\n",
    "                                           dim_ordering = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(train_data, train_targets, validation_data, validation_targets, lr_scheme, num_gpus=1, num_epochs=100,\n",
    "          output_dir='', prev_model=''):\n",
    "        \n",
    "    # reset graph first\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.Graph().as_default(), tf.device('/cpu:0'):\n",
    "        global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        \n",
    "        is_training = tf.placeholder(tf.bool, shape=[], name='is_training')\n",
    "    \n",
    "        # Setting up placeholder, this is where your data enters the graph!\n",
    "        x_pl = tf.placeholder(tf.float32, shape=(None, height, width, depth, channels), name='data_x')\n",
    "        y_pl = tf.placeholder(tf.int32, shape=(None), name='data_y')\n",
    "    \n",
    "        # defining our optimizer\n",
    "        learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "        # Calculate the gradients for each model tower.\n",
    "        tower_grads = []    \n",
    "        losses = []\n",
    "        y = []\n",
    "    \n",
    "        x_splits = tf.split(x_pl, num_or_size_splits=num_gpus)\n",
    "        y_splits = tf.split(y_pl, num_or_size_splits=num_gpus)\n",
    "    \n",
    "        with tf.variable_scope(tf.get_variable_scope()) as scope:\n",
    "            for i in range(num_gpus):\n",
    "                with tf.device('/gpu:%d' % i):\n",
    "                    with tf.name_scope('tower_%d' % (i)) as scope:\n",
    "                        logits = lidc.inference_emphyseme(x_splits[i],\n",
    "                                                          is_training=is_training,\n",
    "                                                          num_outputs=num_classes)\n",
    "                        logits = tf.squeeze(logits)\n",
    "                        l = lidc.loss(logits=logits, labels=y_splits[i], with_regularization=False)\n",
    "\n",
    "                        # Reuse variables for the next tower.\n",
    "                        tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "                        # Calculate the gradients for the batch of data\n",
    "                        grads = optimizer.compute_gradients(l)\n",
    "\n",
    "\n",
    "                        # Keep track of the gradients across all towers.\n",
    "                        tower_grads.append(grads)\n",
    "                        losses.append(l)\n",
    "                        y.append(tf.nn.softmax(logits))\n",
    "\n",
    "        # We must calculate the mean of each gradient. Note that this is the\n",
    "        # synchronization point across all towers.\n",
    "        if (num_gpus>1):\n",
    "            grads = lidc.average_gradients(tower_grads)    \n",
    "        else:\n",
    "            grads = tower_grads[0]\n",
    "    \n",
    "        # Apply the gradients to adjust the shared variables.\n",
    "        apply_gradient_op = optimizer.apply_gradients(grads)\n",
    "    \n",
    "        # Track the moving averages of all trainable variables.\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(lidc.MOVING_AVERAGE_DECAY, global_step)\n",
    "        variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "        with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "            train_op = tf.no_op(name='train')\n",
    "            \n",
    "        # Restore the moving average version of the learned variables for eval.\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(lidc.MOVING_AVERAGE_DECAY)\n",
    "        variables_to_restore = variable_averages.variables_to_restore()\n",
    "        saver = tf.train.Saver(variables_to_restore, max_to_keep=None)\n",
    "        \n",
    "        # restricting memory usage, TensorFlow is greedy and will use all memory otherwise\n",
    "        gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_mem_ratio)\n",
    "        # initialize the Session\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts, \n",
    "                                                allow_soft_placement=True, \n",
    "                                                log_device_placement=True)) # allow_soft_placement=True needed to make batch_normalization work accross GPU\n",
    "            \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        if (prev_model):\n",
    "            print('restoring model', prev_model)\n",
    "            saver.restore(sess, prev_model)            \n",
    "    \n",
    "    train_negative_count = 0\n",
    "    train_positive_count = 0\n",
    "    for i in range(len(train_targets)):\n",
    "        train_negative_count += (train_targets[i]==0).sum()\n",
    "        train_positive_count += (train_targets[i]==1).sum()\n",
    "    n_train_samples = max(train_negative_count,train_positive_count) * num_classes\n",
    "    train_capacity = batch_size * num_gpus\n",
    "    num_batches_train = n_train_samples // train_capacity\n",
    "    \n",
    "    train_iterator_3d = image_gen_3d.flowList(X=train_data, \n",
    "                                              Y=train_targets, \n",
    "                                              batch_size=train_capacity,\n",
    "                                              balance=True,\n",
    "                                              shuffle=True, \n",
    "                                              output_depth=patch_size, \n",
    "                                              output_rows=patch_size, \n",
    "                                              output_cols=patch_size,\n",
    "                                              num_output_channels=channels,\n",
    "                                              scalings=scalings,\n",
    "                                              offsets=offsets)\n",
    "    \n",
    "    val_capacity = batch_size * num_gpus\n",
    "    val_iterator_3d = image_gen_3d_val.flowList(X=validation_data, \n",
    "                                                Y=validation_targets,\n",
    "                                                batch_size=val_capacity,\n",
    "                                                balance=False,\n",
    "                                                shuffle=False,\n",
    "                                                output_depth=patch_size, \n",
    "                                                output_rows=patch_size, \n",
    "                                                output_cols=patch_size,\n",
    "                                                num_output_channels=channels,\n",
    "                                                scalings=scalings,\n",
    "                                                offsets=offsets)\n",
    "    \n",
    "    n_val_samples = 0\n",
    "    for i in range(len(validation_targets)):\n",
    "        n_val_samples += validation_targets[i].shape[0]\n",
    "    num_batches_valid = n_val_samples // val_capacity    \n",
    "\n",
    "    print('training with parameters:\\n\\t- train capacity: %d\\n\\t- val capacity: %d\\n\\t- batch size: %d\\n\\t- patch size: %d\\n\\t'\\\n",
    "          '- num gpu: %d\\n\\t- num epochs: %d\\n\\t- previous model: %s' % (n_train_samples, n_val_samples, batch_size, patch_size,\n",
    "                                                                         num_gpus, num_epochs, prev_model))           \n",
    "    \n",
    "    print('number of training batches per epoch', num_batches_train)\n",
    "    print('number of validation batches per epoch', num_batches_valid)\n",
    "    \n",
    "    train_acc, train_loss = [], []\n",
    "    valid_acc, valid_loss = [], []\n",
    "    test_acc, test_loss = [], []\n",
    "    lr = -1\n",
    "    best_val_loss = -1.\n",
    "    best_val_acc = 0.\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    \n",
    "    train_queue = tpxdli.QueuedIterator(train_iterator_3d, num_batches_train)\n",
    "    val_queue = tpxdli.QueuedIterator(val_iterator_3d, num_batches_valid)\n",
    "    \n",
    "    skip_first_val = False\n",
    "    \n",
    "    try:\n",
    "        # init best_val_loss before training\n",
    "        if not skip_first_val:\n",
    "            confusion_valid = ConfusionMatrix(num_classes)            \n",
    "            val_queue.produce()\n",
    "            for i in range(num_batches_valid):\n",
    "                (batch_val_x, batch_val_y) = val_queue.get_queue().get()\n",
    "                feed_dict_eval = {\n",
    "                    x_pl: batch_val_x,\n",
    "                    y_pl: batch_val_y,\n",
    "                    is_training: False\n",
    "                }\n",
    "                fetches_eval = [y, losses]#, x_splits_list, y_splits, x_splits]\n",
    "                # running the validation\n",
    "                res = sess.run(fetches=fetches_eval, feed_dict=feed_dict_eval)\n",
    "                # collecting and storing predictions\n",
    "                cur_loss = np.sum(res[1])\n",
    "                preds = np.argmax(np.concatenate(res[0]), axis=-1)             \n",
    "                confusion_valid.batch_add(batch_val_y, preds)\n",
    "                if i==0:\n",
    "                    valid_loss = cur_loss/num_gpus\n",
    "                else:\n",
    "                    valid_loss = valid_loss*i/(i+1) + cur_loss/(num_gpus*(i+1))\n",
    "                val_queue.get_queue().task_done()\n",
    "                sys.stdout.write('\\rValidation. batch: %d/%d. loss: %f, acc.: %f'%(i+1,num_batches_valid,valid_loss,confusion_valid.accuracy()))\n",
    "                sys.stdout.flush()\n",
    "                sleep(1)\n",
    "            \n",
    "            best_val_loss = valid_loss\n",
    "            valid_acc_cur = confusion_valid.accuracy()\n",
    "            best_val_acc = valid_acc_cur\n",
    "            print('\\nInitial validation loss and accuracy are: %f / %f'%(best_val_loss, valid_acc_cur))                \n",
    "    \n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            if (lr != lr_scheme[epoch]):\n",
    "                lr = lr_scheme[epoch]\n",
    "                print('using lr', lr)\n",
    "        \n",
    "            t0 = time.time()                \n",
    "                        \n",
    "            confusion_train = ConfusionMatrix(num_classes)\n",
    "            train_queue.produce()\n",
    "            for i in range(num_batches_train):\n",
    "                (batch_train_x, batch_train_y) = train_queue.get_queue().get()\n",
    "                feed_dict_train = {\n",
    "                    x_pl: batch_train_x,\n",
    "                    y_pl: batch_train_y,\n",
    "                    is_training: True, \n",
    "                    learning_rate: lr\n",
    "                }\n",
    "                fetches_train = [train_op, losses, y]\n",
    "                res = sess.run(fetches=fetches_train, feed_dict=feed_dict_train)\n",
    "                cur_loss = np.sum(res[1])\n",
    "                preds = np.argmax(np.concatenate(res[2]), axis=-1)\n",
    "                confusion_train.batch_add(batch_train_y, preds)\n",
    "                if i==0:\n",
    "                    train_loss = cur_loss/(num_gpus)\n",
    "                else:\n",
    "                    train_loss = train_loss*i/(i+1) + cur_loss/(num_gpus*(i+1))                                                \n",
    "                train_queue.get_queue().task_done()\n",
    "                sys.stdout.write('\\rTraining. batch: %d/%d, loss: %f, acc.: %f'%(i+1,num_batches_train,train_loss,confusion_train.accuracy()))\n",
    "                sys.stdout.flush()\n",
    "                sleep(1)\n",
    "                    \n",
    "            t1 = time.time()\n",
    "            epoch_time = t1 - t0\n",
    "        \n",
    "            sys.stdout.write(\"\\n\")\n",
    "        \n",
    "            confusion_valid = ConfusionMatrix(num_classes)            \n",
    "            val_queue.produce()\n",
    "            for i in range(num_batches_valid):\n",
    "                (batch_val_x, batch_val_y) = val_queue.get_queue().get()\n",
    "                feed_dict_eval = {\n",
    "                    x_pl: batch_val_x,\n",
    "                    y_pl: batch_val_y,\n",
    "                    is_training: False\n",
    "                }\n",
    "                fetches_eval = [y, losses]\n",
    "                # running the validation\n",
    "                res = sess.run(fetches=fetches_eval, feed_dict=feed_dict_eval)\n",
    "                # collecting and storing predictions\n",
    "                cur_loss = np.sum(res[1])\n",
    "                preds = np.argmax(np.concatenate(res[0]), axis=-1)             \n",
    "                confusion_valid.batch_add(batch_val_y, preds)\n",
    "                if i==0:\n",
    "                    valid_loss = cur_loss/(num_gpus)\n",
    "                else:\n",
    "                    valid_loss = valid_loss*i/(i+1) + cur_loss/(num_gpus*(i+1))\n",
    "                val_queue.get_queue().task_done()\n",
    "                sys.stdout.write('\\rValidation. batch: %d/%d, loss: %f, acc.: %f'%(i+1,num_batches_valid,valid_loss,confusion_valid.accuracy()))\n",
    "                sys.stdout.flush()\n",
    "                sleep(1)\n",
    "                            \n",
    "            sys.stdout.write(\"\\n\")\n",
    "            \n",
    "            train_acc_cur = confusion_train.accuracy()\n",
    "            valid_acc_cur = confusion_valid.accuracy()\n",
    "\n",
    "            train_acc += [train_acc_cur]\n",
    "            valid_acc += [valid_acc_cur]\n",
    "            print (\"Epoch %i: train loss %e, train acc. %f, valid loss %f, valid acc %f, epoch time %.2f s \" \\\n",
    "            % (epoch+1, train_loss, train_acc_cur, valid_loss, valid_acc_cur, epoch_time))\n",
    "        \n",
    "            if (best_val_loss<0):\n",
    "                best_val_loss = valid_loss\n",
    "            \n",
    "            if ((best_val_loss>=0) and (valid_loss<best_val_loss)):\n",
    "                print('val loss improved from %f to %f, saving model' % (best_val_loss, valid_loss))\n",
    "                best_val_loss = valid_loss\n",
    "                if (output_dir):\n",
    "                    filename = output_dir + 'best_model_loss'\n",
    "                    print('saving model to file:',filename)\n",
    "                    saver.save(sess, filename)\n",
    "                    \n",
    "            if (best_val_acc<valid_acc_cur):\n",
    "                print('val acc improved from %f to %f, saving model' % (best_val_acc, valid_acc_cur))\n",
    "                best_val_acc = valid_acc_cur\n",
    "                if (output_dir):\n",
    "                    filename = output_dir + 'best_model_acc'\n",
    "                    print('saving model to file:',filename)\n",
    "                    saver.save(sess, filename)\n",
    "                        \n",
    "            if (((epoch+1)%10)==0):\n",
    "                saver.save(sess, output_dir+'checkpoint_epoch')\n",
    "                \n",
    "            epoch += 1\n",
    "            \n",
    "            train_loss = 0.\n",
    "            valid_loss = 0.\n",
    "\n",
    "    except KeyboardInterrupt:        \n",
    "        pass\n",
    "    \n",
    "    train_queue.get_queue().join()\n",
    "    val_queue.get_queue().join()\n",
    "    \n",
    "    sess.close()\n",
    "\n",
    "    epoch = np.arange(len(train_acc))\n",
    "    plt.figure()\n",
    "    plt.plot(epoch, train_acc,'r', epoch, valid_acc,'b')\n",
    "    plt.legend(['Train Acc','Val Acc'])\n",
    "    plt.xlabel('Epochs'), plt.ylabel('Acc'), plt.ylim([0.6,1.03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "prev_model = ''\n",
    "\n",
    "output_directory = 'model/'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "    \n",
    "lr_scheme = np.zeros(shape=(num_epochs), dtype=np.float32)\n",
    "lr = 1e-3\n",
    "lr_decay = 10.\n",
    "lr_scheme[0:5] = lr\n",
    "lr /= lr_decay\n",
    "lr_scheme[5:] = lr\n",
    "    \n",
    "train_data_list = [train_data, train_hn_data, train_hn2_data, train_hn3_data]\n",
    "train_target_list = [train_targets, train_hn_targets, train_hn2_targets, train_hn3_targets]\n",
    "validation_data_list = [validation_data, validation_hn_data, validation_hn2_data, validation_hn3_data]\n",
    "validation_target_list = [validation_targets, validation_hn_targets, validation_hn2_targets, validation_hn3_targets]\n",
    "\n",
    "# train model    \n",
    "train(train_data=train_data_list, \n",
    "      train_targets=train_target_list,\n",
    "      validation_data=validation_data_list, \n",
    "      validation_targets=validation_target_list,\n",
    "      lr_scheme=lr_scheme,\n",
    "      num_gpus=num_gpus,\n",
    "      num_epochs=num_epochs,      \n",
    "      output_dir=output_directory,\n",
    "      prev_model=prev_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
